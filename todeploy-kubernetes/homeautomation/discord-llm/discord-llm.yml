apiVersion: apps/v1
kind: Deployment
metadata:
  name: discord-llm
  labels:
    app: discord-llm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: discord-llm
  template:
    metadata:
      labels:
        app: discord-llm
    spec:
      # NonEssential
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: la1r.workload/nonessential
                operator: In
                values:
                - "true"
                
      volumes:
      - name: discord-llm-volume
        persistentVolumeClaim:
          claimName: discord-llm-claim
      - name: discord-llm-script
        configMap:
          name: discord-llm-script
          defaultMode: 0755
      containers:
      - name: discord-llm
        image: python:3.9-slim
        command: ["sh", "-c", "pip install requests && python /scripts/discord-llm.py"]
        volumeMounts:
        - name: discord-llm-script
          mountPath: /scripts
        - name: discord-llm-volume
          mountPath: /storage
        # - name: pyrunner
        #   mountPath: /root/pyrunner/runner.py
        #   subPath: runner.py
        # resources:
        #   limits:
        #     nvidia.com/gpu: 1 # Adjust if you need more GPUs or specific resource limits
# ---
# apiVersion: v1
# kind: Service
# metadata:
#   labels:
#     app: discord-llm
#   name: discord-llm
# spec:
#   ports:
#   - name: rpc
#     targetPort: 8899
#     port: 8899
#   selector:
#     app: discord-llm
#   type: ClusterIP

# ---
# apiVersion: v1
# kind: Service
# metadata:
#   labels:
#     app: discord-llm-lb
#   name: discord-llm-lb
# spec:
#   ports:
#   - name: rpc
#     targetPort: 8899
#     port: 8899
#   selector:
#     app: discord-llm
#   loadBalancerIP: 192.168.6.78
#   type: LoadBalancer