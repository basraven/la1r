apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama
  labels:
    app: ollama
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ollama
  template:
    metadata:
      labels:
        app: ollama
    spec:
      # Essential
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            preference:
              matchExpressions:
              - key: la1r.workload/essential
                operator: In
                values:
                - "true"
      priorityClassName: essential
                
      volumes:
      - name: ollama-volume
        persistentVolumeClaim:
          claimName: ollama-claim
      # - name: pyrunner
      #   configMap:
      #     name: pyrunner
      #     defaultMode: 0755
      containers:
      - name: ollama
        image: ollama/ollama:latest
        # command: [ "pytest", "my_first_test.py", "--browser=chrome", "--headless"]
        ports:
        - containerPort: 11434
          name: http
        # env:
        # - name: RUST_LOG
        #   value: "info,solana_metrics::metrics=warn"
        volumeMounts:
        - name: ollama-volume
          mountPath: /root/.ollama
        # - name: pyrunner
        #   mountPath: /root/pyrunner/runner.py
        #   subPath: runner.py
        # resources:
        #   limits:
        #     nvidia.com/gpu: 1 # Adjust if you need more GPUs or specific resource limits
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: ollama
  name: ollama
spec:
  ports:
  - name: http
    targetPort: 11434
    port: 11434
  selector:
    app: ollama
  type: ClusterIP

---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: ollama-lb
  name: ollama-lb
spec:
  ports:
  - name: http
    targetPort: 11434
    port: 11434
  selector:
    app: ollama
  loadBalancerIP: 192.168.6.79
  type: LoadBalancer